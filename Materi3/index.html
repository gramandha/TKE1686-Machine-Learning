<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Pertemuan 4-5: Klaster (K-Means, Hirarki Klaster, DBSCAN) - Machine Learning</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Pertemuan 4-5: Klaster (K-Means, Hirarki Klaster, DBSCAN)";
        var mkdocs_page_input_path = "Materi3.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Machine Learning
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Materi</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../Materi1/">Pertemuan 2: Pengantar Machine Learning pada bidang Teknik Elektro</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../Materi2/">Pertemuan 3: Pengumpulan, Pemrosesan dan Visualisasi pada Dataset</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Pertemuan 4-5: Klaster (K-Means, Hirarki Klaster, DBSCAN)</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#algoritma-klaster-yang-akan-di-pelajari">Algoritma Klaster yang akan di pelajari</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#k-means">K-Means</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#langkah-langkah-k-means">Langkah-Langkah K-Means</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#penetuan-ngukuran-jarak-bisa-menggunakan-beberapa-metode-seperti-contohnya">Penetuan ngukuran jarak bisa menggunakan beberapa metode, seperti contohnya:</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#contoh-program-k-means">Contoh Program K-Means</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#hirarki-klaster-hirarical-cluster">Hirarki Klaster (Hirarical Cluster)</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#contoh-kasus">Contoh kasus:</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#tipe-dari-hirarki-klaster">Tipe dari Hirarki klaster</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#langkah-langkah-metode-hierarchical-clustering-dengan-agglomerative">Langkah-langkah metode hierarchical clustering dengan agglomerative:</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#menggunakan-dendogram">Menggunakan Dendogram</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#contoh-program-hirarki-klaster">Contoh program hirarki klaster</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#dbscan-density-based-spatial-clustering-of-applications">DBSCAN (Density-Based Spatial Clustering of Applications)</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#konsep">Konsep</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#langkah-langkah-algoritma-dbscan">Langkah-langkah algoritma DBSCAN</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#terdapat-tiga-jenis-titik-setelah-pengelompokan-dbscan-selesai">Terdapat tiga jenis titik setelah pengelompokan DBSCAN selesai:</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#contoh-program-dbscan">Contoh program DBSCAN</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#tugas-materi-klaster">Tugas Materi Klaster</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../Materi4/">Pertemuan 6: Klasifikasi</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Tugas</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../LKM1/">LKM 1</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../LKM2/">LKM 2</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../LKM3/">LKM 3</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../LKM4/">LKM 4</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Machine Learning</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Materi</li>
      <li class="breadcrumb-item active">Pertemuan 4-5: Klaster (K-Means, Hirarki Klaster, DBSCAN)</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/gramandha/TKE1686-Machine-Learning/edit/master/docs/Materi3.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="pertemuan-4-5-klaster-k-means-hirarki-klaster-dbscan">Pertemuan 4-5: Klaster (K-Means, Hirarki Klaster, DBSCAN)</h1>
<p><strong>[TKE1686] MK Machine Learning (3-SKS)</strong></p>
<p>oleh: Gramandha Wega Intyanto, S.ST., M.T.</p>
<h2 id="algoritma-klaster-yang-akan-di-pelajari">Algoritma Klaster yang akan di pelajari</h2>
<ol>
<li>K-Means</li>
<li>Hirarki Klaster</li>
<li>DBSCAN</li>
</ol>
<p><img alt="gambar 1" src="../assets/metode_cluster.png" /></p>
<h2 id="k-means">K-Means</h2>
<p>Algoritma K-means adalah salah satu algoritma clustering yang bersifat iteratif yang mencoba untuk mempartisi
dataset menjadi subkelompok non-overlapping berbeda yang ditentukan oleh K (cluster) di mana setiap titik data
hanya dimiliki oleh satu kelompok.</p>
<p>K-Means mencoba membuat titik data intra-cluster semirip mungkin sambil dengan titik data yang lain pada satu
cluster. <strong>K-Means menetapkan poin data ke cluster sedemikian rupa sehingga jumlah jarak kuadrat antara titik data dan pusat massa cluster (rata-rata aritmatika dari semua titik data yang termasuk dalam cluster itu) minimal.</strong>
<strong>Semakin sedikit variasi</strong> yang kita miliki dalam cluster, <strong>semakin homogen (serupa)</strong> titik data dalam cluster yang
sama.</p>
<h3 id="langkah-langkah-k-means">Langkah-Langkah K-Means</h3>
<ol>
<li>Memilih jumlah cluster awal (K) yang ingin dibuat</li>
</ol>
<p><img alt="gambar 1" src="../assets/data_random.png" /></p>
<ol>
<li>Memilih titik secara random sebanyak K buah, di mana titik ini akan menjadi pusat (centroid) dari masing-masing kelompok (clusters).</li>
</ol>
<p><img alt="gambar 2" src="../assets/centorid.png" /></p>
<ol>
<li>Dari dataset yang kita miliki, buat dataset yang terdekat dengan titik centroid sebagai bagian dari cluster tersebut. Sehingga secara total akan terbentuk clusters sebanyak K buah.</li>
</ol>
<p><img alt="gambar 3" src="../assets/klaster.png" /></p>
<ol>
<li>Lakukan kalkulasi, dan tempatkan pusat centroid yang baru untuk setiap cluster-nya. Langkah ini dilakukan untuk menemukan centroid yang paling tepat untuk maisng-masing klaster.</li>
</ol>
<p><img alt="gambar 4" src="../assets/centroid_geser.png" /></p>
<ol>
<li>
<p>Dari dataset yang kita miliki ambil titik centroid terdekat, sehingga dataset tadi menjadi bagian
dari cluster tersebut. Jika masih ada data yang berubah kelompok (pindah cluster), kembali ke langkah </p>
</li>
<li>
<p>Jika tidak, maka cluster yang terbentuk sudah baik.</p>
</li>
</ol>
<video width="320" height="240" controls>
  <source src="https://www.youtube.com/watch?v=6QV4vPpDxKQ&t=50s" type="video/mp4">
</video>

<p><img alt="gambar 4" src="../assets/k-means.gif" /></p>
<h3 id="penetuan-ngukuran-jarak-bisa-menggunakan-beberapa-metode-seperti-contohnya">Penetuan ngukuran jarak bisa menggunakan beberapa metode, seperti contohnya:</h3>
<ul>
<li>
<p>Ecluidean Distance : Jarak dihitung sebagai <strong>panjang garis lurus</strong> antara dua titik dalam ruang Euclidean. Ini adalah bentuk jarak yang paling umum digunakan dalam analisis data dan pembelajaran mesin.</p>
<p>Formula Euclidean Distance untuk dua titik <span class="arithmatex">\((x_1, y_1)\)</span> dan <span class="arithmatex">\((x_2, y_2)\)</span> :
        <span class="arithmatex">\(d_{\text{Euclidean}}(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\)</span></p>
</li>
<li>
<p>Manhattan Distance : Jarak dihitung sebagai jumlah selisih absolut antara koordinat titik data dan centroid.</p>
<p>Formula Manhattan Distance untuk dua titik <span class="arithmatex">\((x_1, y_1)\)</span> dan <span class="arithmatex">\((x_2, y_2)\)</span> :
        <span class="arithmatex">\(d_{\text{Manhattan}}(x, c) = \sum_{i=1}^{n} |x_i - y_i|\)</span></p>
</li>
<li>
<p>atau menggunakan metode lain Minkowski, Cosine, Mahalanobis, Chebyshev Distance</p>
</li>
</ul>
<h3 id="contoh-program-k-means">Contoh Program K-Means</h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Mengimpor library</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Mengimpor dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;datasets/Customer.csv&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Menggunakan metode elbow untuk menentukan angka cluster yang tepat</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="n">wcss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">i</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">wcss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">wcss</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Method&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Cluster Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;WCSS&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Menjalankan K-Means Clustering ke dataset</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">init</span> <span class="o">=</span> <span class="s1">&#39;k-means++&#39;</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">y_kmeans</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Visualisasi hasil clusters</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Cluster 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Cluster 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;magenta&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Cluster 3&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Cluster 4&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_kmeans</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Cluster 5&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;yellow&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Centroids&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Consumers Cluster&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Yearly Salary&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Yearly expense rating (1-100)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../assets/output_12_0.png" /></p>
<p><img alt="png" src="../assets/output_12_1.png" /></p>
<h2 id="hirarki-klaster-hirarical-cluster">Hirarki Klaster <em>(Hirarical Cluster)</em></h2>
<p>Pengelompokan hierarki adalah Teknik clustering dengan memisahkan data ke dalam kelompok berdasarkan beberapa ukuran
kesamaan, menemukan cara untuk mengukur bagaimana mereka sama dan berbeda, dan selanjutnya mempersempit data.</p>
<h3 id="contoh-kasus">Contoh kasus:</h3>
<p>Pertama, terdapat empat mobil yang dapat masukkan ke dalam dua kelompok jenis mobil: sedan dan SUV. 
Selanjutnya, HC akan menggabungkan sedan dan SUV. 
Untuk langkah terakhir, yaitu mengelompokkan semuanya ke dalam satu cluster dan selesai ketika kita hanya memiliki satu cluster.</p>
<p><img alt="gambar 5" src="../assets/kelompok_mobil.png" /></p>
<h3 id="tipe-dari-hirarki-klaster">Tipe dari Hirarki klaster</h3>
<ol>
<li>Divisive: Pengelompokan divisif dikenal sebagai pendekatan top-down, yaitu mengambil cluster besar dan mulai membaginya menjadi
dua, tiga, empat, atau lebih cluster.</li>
<li>Agglomerative: Pengelompokan aglomeratif dikenal sebagai pendekatan bottom-up, yaitu pengelompokan dimulai dari cluster kecil menuju satu
cluster besar.</li>
</ol>
<p><img alt="gambar" src="../assets/hirarki.png" /></p>
<h3 id="langkah-langkah-metode-hierarchical-clustering-dengan-agglomerative">Langkah-langkah metode hierarchical clustering dengan agglomerative:</h3>
<ol>
<li>Buat setiap data poin dalam dataset menjadi sebuah cluster, sehi8ngga untuk N data kita memiliki N cluster. Misalnya jika
jumlah row data adalah 500 maka akan terdapat 500 cluster.</li>
<li>Cari dua poin/2 cluster yang saling berdekatan untuk digabung menjadi satu cluster sehingga jumlah cluster menjadi lebih
kecil.</li>
<li>Cari 2 cluster lagi yang berdekatan dengan yang lain (termasuk dengan kluster yang baru saja dibuat di langkah 2 jika
memang cluster tersebut memiliki jarak terdekat dengan kluster lain), dan jadikan dua cluster terdekat ini menjadi 1 kluster.
Dengan demikian, sekarang kita memiliki N-2 kluster.</li>
<li>Langkah ketiga akan diulang terus hingga mendapatkan satu buah cluster besar.</li>
</ol>
<h3 id="menggunakan-dendogram">Menggunakan Dendogram</h3>
<ol>
<li>Sama seperti pada contoh hierarchical clustering sebelumnya, terdapat enam titik dalam satu diagram. Grafik yang atas adalah grafik awal dan yang bawah adalah grafik dendogram.</li>
</ol>
<p><img alt="gambar 5" src="../assets/step1_ha.png" /></p>
<ol>
<li>Sama seperti ilustrasi pada hierarchical clustering, langkah pertama adalah menentukan dua titik terdekat kemudian menerjemahkannya ke dalam diagram dendogram.</li>
</ol>
<p><img alt="gambar 5" src="../assets/step2_ha.png" /></p>
<ol>
<li>Mencari lagi dua cluster yang berdekatan untuk digabungkan menjadi satu cluster lagi. Tinggi diagram Dendogram berbeda-beda sesuai dengan hasil penghitungan Euclidean Distancenya.</li>
</ol>
<p><img alt="gambar 5" src="../assets/step3_ha.png" /></p>
<ol>
<li>
<p>Proses yang ketiga diulang lagi dengan mencari dua cluster yang terdekat. Jika dua cluster yang digabungkan sebelumnya adalah cluster antara dua titik maka cara menerjemahkan dalam dendogram.
<img alt="gambar 5" src="../assets/step4_ha.png" /></p>
</li>
<li>
<p>Mengulang proses dengan menggabungkan cluster yang sudah ada, Pada gambar disamping tampak bahwa dua cluster terakhir merupakan gabungan dari cluster (dua titik yang menjadi satu cluster) pada proses awal.</p>
</li>
</ol>
<p><img alt="gambar 5" src="../assets/step5_ha.png" /></p>
<ol>
<li>Proses akan berhenti setelah semua cluster telah tergabung menjadi satu cluster besar.</li>
</ol>
<p><img alt="gambar 5" src="../assets/step6_ha.png" /></p>
<ol>
<li>Untuk menentukan berapa jumlah cluster yang paling sesuai pada dats set yang diujikan dapat dianalisa melalui dendogram. Yaitu dengan menentukan garis grafik dendogram yang paling panjang yang tidak terkena potongan atau bisa juga dengan menentukan nilai threshold.</li>
</ol>
<p><img alt="gambar 5" src="../assets/step7_ha.png" /></p>
<h3 id="contoh-program-hirarki-klaster">Contoh program hirarki klaster</h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Mengimpor library</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.cluster.hierarchy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">AgglomerativeClustering</span>

<span class="c1"># Mengimpor dataset</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;datasets/Customer.csv&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset berhasil dimuat!&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error: File &#39;Customer.csv&#39; tidak ditemukan. Pastikan file berada di direktori yang benar.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># Pastikan dataset memiliki cukup kolom</span>
<span class="k">if</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error: Dataset tidak memiliki kolom yang cukup untuk clustering.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># Mengambil fitur yang akan digunakan</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Menampilkan dendrogram untuk menentukan jumlah cluster</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">dendrogram</span> <span class="o">=</span> <span class="n">sch</span><span class="o">.</span><span class="n">dendrogram</span><span class="p">(</span><span class="n">sch</span><span class="o">.</span><span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;ward&#39;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Dendrogram&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Consumer&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Euclidean Distance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Menjalankan Hierarchical Clustering dengan parameter yang diperbaiki</span>
<span class="n">hc</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">,</span> <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="n">y_hc</span> <span class="o">=</span> <span class="n">hc</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Visualisasi hasil clustering</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;cyan&#39;</span><span class="p">,</span> <span class="s1">&#39;magenta&#39;</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Cluster 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Cluster 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Cluster 3&#39;</span><span class="p">,</span> <span class="s1">&#39;Cluster 4&#39;</span><span class="p">,</span> <span class="s1">&#39;Cluster 5&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y_hc</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Consumers Cluster&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Yearly Salary&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Yearly Expense Rating (1-100)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Dataset berhasil dimuat!
</code></pre></div>
<p><img alt="png" src="../assets/output_19_1.png" /></p>
<p><img alt="png" src="../assets/output_19_2.png" /></p>
<h2 id="dbscan-density-based-spatial-clustering-of-applications">DBSCAN (Density-Based Spatial Clustering of Applications)</h2>
<p>Density-Based Spatial Clustering of Applications with Noise (DBSCAN) adalah
algoritma dasar untuk pengelompokan berbasis density. Algoritma ini dapat
menemukan cluster dengan berbagai bentuk dan ukuran dari sejumlah besar data,
yang mengandung noise dan outlier.</p>
<p>ketika data cluster berbentuk arbiter atau ingin mendeteksi cluster out lier, maka DBSCAN merupaka
Teknik cluster yang sesuai
<img alt="gambar 5" src="../assets/DBScan.png" /></p>
<p>Algoritma DBSCAN menggunakan dua parameter yaitu:</p>
<ol>
<li><strong>minPts</strong>: Jumlah minimum titik (ambang batas) yang dikelompokkan bersama agar suatu wilayah dianggap density.</li>
<li><strong>eps (ε)</strong>: Ukuran jarak yang akan digunakan untuk menemukan titik-titik di sekitar titik mana pun.</li>
</ol>
<p><img alt="Screenshot from 2025-03-19 10-26-33.png" src="../assets/parameter-dbscan.png" /></p>
<p>Kedua parameter ini dapat diterapkan dengan baik dengan menggunakan dua konsep yaitu Density Reachability dan Density Connectivity</p>
<h3 id="konsep">Konsep</h3>
<ol>
<li><strong>Reachability</strong> pada konsep ini, untuk menentukan kepadatan dialukan dengan menetapkan suatu titik yang dapat dijangkau dari yang lain jika terletak dalam jarak tertentu (eps) darinya.</li>
<li><strong>Connectivity</strong>, konsep ini melakukan pendekatan chaining berbasis transitivitas untuk menentukan apakah titik terletak di cluster tertentu. Misalnya, titik p dan q dapat dihubungkan jika <span class="arithmatex">\(p-&gt;r-&gt;s-&gt;t-&gt;q\)</span>, di mana <span class="arithmatex">\(x-&gt;y\)</span> berarti <span class="arithmatex">\(x\)</span> berada di sekitar (neighborhood) <span class="arithmatex">\(y\)</span>.</li>
</ol>
<h3 id="langkah-langkah-algoritma-dbscan">Langkah-langkah algoritma DBSCAN</h3>
<ol>
<li>Algoritma dimulai dengan mengambil titik dalam kumpulan data secara random (sampai semua titik telah dikunjungi).</li>
<li>Jika setidaknya ada titik 'minPoint' dalam radius ke titik tersebut, maka dapat dianggap semua titik ini sebagai bagian dari cluster yang sama.</li>
<li>Cluster kemudian diperluas dengan mengulangi perhitungan lingkungan secara rekursif untuk setiap titik tetangga.</li>
</ol>
<p><img alt="gambar 5" src="../assets/dbscan_view.png" />
<img alt="gambar 5" src="../assets/dbscan.gif" /></p>
<h3 id="terdapat-tiga-jenis-titik-setelah-pengelompokan-dbscan-selesai">Terdapat tiga jenis titik setelah pengelompokan DBSCAN selesai:</h3>
<ol>
<li>Core adalah titik yang memiliki setidaknya m titik dalam jarak n dari dirinya sendiri.</li>
<li>Border adalah titik yang memiliki setidaknya satu titik Inti pada jarak n.</li>
<li>Noise adalah titik yang bukan Core atau Border. Dan ia memiliki kurang dari m titik dalam jarak n
dari dirinya sendiri.</li>
</ol>
<p><img alt="image.png" src="../assets/titik_dbscan.png" /></p>
<h3 id="contoh-program-dbscan">Contoh program DBSCAN</h3>
<div class="highlight"><pre><span></span><code><span class="c1">#Penerapan DBSCAN pada cluster spherical data.</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># Generate sample data</span>
<span class="n">centers</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">X</span><span class="p">,</span> <span class="n">labels_true</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="n">centers</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Menghitung DBSCAN</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">core_samples_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">db</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">core_samples_mask</span><span class="p">[</span><span class="n">db</span><span class="o">.</span><span class="n">core_sample_indices_</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Number of clusters in labels, ignoring noise if present.</span>
<span class="n">n_clusters_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">n_noise_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Estimated number of clusters: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">n_clusters_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Estimated number of noise points: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">n_noise_</span><span class="p">)</span>
<span class="c1"># print(&quot;Homogeneity: %0.3f&quot; % metrics.homogeneity_score(labels_true, labels))</span>
<span class="c1"># print(&quot;Completeness: %0.3f&quot; % metrics.completeness_score(labels_true, labels))</span>
<span class="c1"># print(&quot;V-measure: %0.3f&quot; % metrics.v_measure_score(labels_true, labels))</span>
<span class="c1"># print(&quot;Adjusted Rand Index: %0.3f&quot;</span>
<span class="c1">#       % metrics.adjusted_rand_score(labels_true, labels))</span>
<span class="c1"># print(&quot;Adjusted Mutual Information: %0.3f&quot;</span>
<span class="c1">#       % metrics.adjusted_mutual_info_score(labels_true, labels))</span>
<span class="c1"># print(&quot;Silhouette Coefficient: %0.3f&quot;</span>
<span class="c1">#       % metrics.silhouette_score(X, labels))</span>

<span class="c1"># Plot result</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>


<span class="c1"># Black removed and is used for noise instead.</span>
<span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">(</span><span class="n">each</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">))]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Black used for noise.</span>
        <span class="n">col</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="n">class_member_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>

    <span class="n">xy</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">class_member_mask</span> <span class="o">&amp;</span> <span class="n">core_samples_mask</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">col</span><span class="p">),</span>
             <span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

    <span class="n">xy</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">class_member_mask</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">core_samples_mask</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">col</span><span class="p">),</span>
             <span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Estimated number of clusters: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">n_clusters_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Estimated number of clusters: 3
Estimated number of noise points: 20
</code></pre></div>
<p><img alt="png" src="../assets/output_26_1.png" /></p>
<h3 id="tugas-materi-klaster">Tugas Materi Klaster</h3>
<p>Cari dataset yang perlu untuk di klaster atau dari dataset yang Anda punya, silahkan lakukan klaster dari featur yang Anda tentukan, 
kemudian klaster dengan K-mean Klaster, Hirarki Klaster, dan DBscan.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../Materi2/" class="btn btn-neutral float-left" title="Pertemuan 3: Pengumpulan, Pemrosesan dan Visualisasi pada Dataset"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../Materi4/" class="btn btn-neutral float-right" title="Pertemuan 6: Klasifikasi">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/gramandha/TKE1686-Machine-Learning" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../Materi2/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../Materi4/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="https://unpkg.com/mermaid@10/dist/mermaid.min.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
